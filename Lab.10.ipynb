{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "97sFXNijmb0N"
      },
      "outputs": [],
      "source": [
        "# Section 1: Initialize constants\n",
        "\n",
        "num_layers = 96\n",
        "dim_model = 12288\n",
        "vocab_size = 50000\n",
        "dim_ff = dim_model * 4  # feedforward dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 2: Embedding + Unembedding parameters\n",
        "\n",
        "embedding_params = dim_model * vocab_size\n",
        "unembedding_params = dim_model * vocab_size\n",
        "\n",
        "total_embedding_unembedding = embedding_params + unembedding_params\n",
        "total_embedding_unembedding\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l03CyhaZmjG_",
        "outputId": "edd679bb-bdf5-4024-b0b9-94f2efac9cd9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1228800000"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 3: Attention parameters per layer\n",
        "\n",
        "key_params = dim_model * dim_model\n",
        "query_params = dim_model * dim_model\n",
        "value_params = dim_model * dim_model\n",
        "attention_output_params = dim_model * dim_model\n",
        "\n",
        "attention_params_per_layer = key_params + query_params + value_params + attention_output_params\n",
        "\n",
        "# Total attention parameters across all layers\n",
        "total_attention_params = num_layers * attention_params_per_layer\n",
        "total_attention_params\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OmMDpKumlru",
        "outputId": "4ba2e72e-7144-4186-fa2a-f9d1d4649759"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57982058496"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 4: Feedforward parameters per layer\n",
        "\n",
        "feedforward_down_params = dim_model * dim_ff\n",
        "feedforward_up_params = dim_ff * dim_model\n",
        "\n",
        "feedforward_params_per_layer = feedforward_down_params + feedforward_up_params\n",
        "\n",
        "# Total feedforward parameters across all layers\n",
        "total_feedforward_params = num_layers * feedforward_params_per_layer\n",
        "total_feedforward_params\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxYfJ2O3mqom",
        "outputId": "24ae2708-9cea-4676-801a-2cd967bfaead"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115964116992"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 5: Calculate total parameters\n",
        "\n",
        "total_params = total_embedding_unembedding + total_attention_params + total_feedforward_params\n",
        "total_params\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6NmaKv6mtV2",
        "outputId": "d9b00805-1977-448a-8c8b-06592db275d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175174975488"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Section 6: Print total parameters in billions\n",
        "\n",
        "total_params_billion = total_params / 1e9\n",
        "print(f\"Total parameters in GPT-3 model: {total_params_billion:.2f} billion\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjCgogGDmwsF",
        "outputId": "a9f9f58c-5ecd-4e66-a766-53e20f33cac9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters in GPT-3 model: 175.17 billion\n"
          ]
        }
      ]
    }
  ]
}