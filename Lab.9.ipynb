{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Input tensor (3 words, each with 4 features)\n",
        "x = tf.constant([\n",
        "    [0.1, 0.2, 0.3, 0.4],\n",
        "    [0.5, 0.6, 0.7, 0.8],\n",
        "    [0.9, 1.0, 1.1, 1.2]\n",
        "], dtype=tf.float32)\n",
        "print(\"Input tensor x:\")\n",
        "print(x.numpy())\n"
      ],
      "metadata": {
        "id": "nicffFDmm_FD",
        "outputId": "055383b5-443b-4007-e7c7-02aa0df69c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tensor x:\n",
            "[[0.1 0.2 0.3 0.4]\n",
            " [0.5 0.6 0.7 0.8]\n",
            " [0.9 1.  1.1 1.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Projection matrices for Q, K, V (weights)\n",
        "W_Q = tf.constant([\n",
        "    [0.1, 0.2, 0.3],\n",
        "    [0.4, 0.5, 0.6],\n",
        "    [0.7, 0.8, 0.9],\n",
        "    [1.0, 1.1, 1.2]\n",
        "], dtype=tf.float32)\n",
        "\n",
        "W_K = W_Q  # Keys use the same matrix as Queries in this example\n",
        "\n",
        "W_V = tf.constant([\n",
        "    [0.1, 0.2],\n",
        "    [0.3, 0.4],\n",
        "    [0.5, 0.6],\n",
        "    [0.7, 0.8]\n",
        "], dtype=tf.float32)\n",
        "\n",
        "print(\"Projection matrix W_Q:\\n\", W_Q.numpy())\n",
        "print(\"Projection matrix W_V:\\n\", W_V.numpy())\n"
      ],
      "metadata": {
        "id": "wGTYR_Wgn88R",
        "outputId": "7b70bcc1-e349-48c5-8b96-0c862b663dd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projection matrix W_Q:\n",
            " [[0.1 0.2 0.3]\n",
            " [0.4 0.5 0.6]\n",
            " [0.7 0.8 0.9]\n",
            " [1.  1.1 1.2]]\n",
            "Projection matrix W_V:\n",
            " [[0.1 0.2]\n",
            " [0.3 0.4]\n",
            " [0.5 0.6]\n",
            " [0.7 0.8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project input x to Queries, Keys, Values by multiplying with respective weights\n",
        "queries = tf.matmul(x, W_Q)\n",
        "keys = tf.matmul(x, W_K)\n",
        "values = tf.matmul(x, W_V)\n",
        "\n",
        "print(\"Queries matrix:\\n\", queries.numpy())\n",
        "print(\"Keys matrix:\\n\", keys.numpy())\n",
        "print(\"Values matrix:\\n\", values.numpy())\n"
      ],
      "metadata": {
        "id": "gq8OcOqCoo1Y",
        "outputId": "273c6ab2-e04c-4d34-ae3c-f4361e88b3cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queries matrix:\n",
            " [[0.70000005 0.8000001  0.90000004]\n",
            " [1.5799999  1.8400002  2.1       ]\n",
            " [2.46       2.88       3.3000002 ]]\n",
            "Keys matrix:\n",
            " [[0.70000005 0.8000001  0.90000004]\n",
            " [1.5799999  1.8400002  2.1       ]\n",
            " [2.46       2.88       3.3000002 ]]\n",
            "Values matrix:\n",
            " [[0.5       0.6      ]\n",
            " [1.14      1.4000001]\n",
            " [1.78      2.2      ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate attention scores as dot product of Queries and Keys transpose\n",
        "scores = tf.matmul(queries, keys, transpose_b=True)\n",
        "\n",
        "print(\"Attention scores matrix (Q*K^T):\")\n",
        "print(scores.numpy())\n"
      ],
      "metadata": {
        "id": "3T-mOKlHorB4",
        "outputId": "60402cf8-ab92-4505-d293-a9d8d98f16ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention scores matrix (Q*K^T):\n",
            "[[ 1.9400002  4.4680004  6.996001 ]\n",
            " [ 4.4680004 10.292     16.116001 ]\n",
            " [ 6.996001  16.116001  25.236002 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale scores by sqrt of key dimension (sqrt(3))\n",
        "scaled_scores = scores / tf.math.sqrt(tf.cast(tf.shape(keys)[-1], tf.float32))\n",
        "\n",
        "print(\"Scaled attention scores:\")\n",
        "print(scaled_scores.numpy())\n",
        "\n",
        "# Apply softmax to get attention weights (probabilities)\n",
        "weights = tf.nn.softmax(scaled_scores, axis=-1)\n",
        "\n",
        "print(\"Attention weights (after softmax):\")\n",
        "print(weights.numpy())\n"
      ],
      "metadata": {
        "id": "jMMTnj0nqNrr",
        "outputId": "6fea7200-ca1f-4b7c-ada9-224d26ae5e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled attention scores:\n",
            "[[ 1.1200596  2.5796013  4.039143 ]\n",
            " [ 2.5796013  5.942089   9.304578 ]\n",
            " [ 4.039143   9.304578  14.570013 ]]\n",
            "Attention weights (after softmax):\n",
            "[[4.1966923e-02 1.8062508e-01 7.7740800e-01]\n",
            " [1.1589993e-03 3.3449762e-02 9.6539128e-01]\n",
            " [2.6561420e-05 5.1404452e-03 9.9483299e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply attention weights by Values to get final context vectors\n",
        "context = tf.matmul(weights, values)\n",
        "\n",
        "print(\"Context vectors (output of attention):\")\n",
        "print(context.numpy())\n"
      ],
      "metadata": {
        "id": "XW_UwdmtqP7K",
        "outputId": "237dafce-979b-42c8-b8d0-c95bd90bae62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context vectors (output of attention):\n",
            "[[1.6106822 1.9883529]\n",
            " [1.7571087 2.171386 ]\n",
            " [1.776676  2.1958451]]\n"
          ]
        }
      ]
    }
  ]
}